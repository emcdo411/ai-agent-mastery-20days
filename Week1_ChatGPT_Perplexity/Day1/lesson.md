# ‚ö° Day 1 ‚Äî Tool Setup, Trust & First Comparison (with ChatGPT-5)

## üìå Objective

* Create free accounts for **ChatGPT-5** and **Perplexity AI**.
* Understand **responsible AI use** (what‚Äôs safe to paste, what‚Äôs not).
* Compare their strengths and weaknesses on the *same local query*.
* Learn the **advantages of ChatGPT-5 vs. ChatGPT-3.5**.
* Produce and document your **first AI research output**, with a **country-specific focus**.
* Log, reflect, and commit results following vibe coding discipline.

---

## üõ† Steps (30‚Äì45 min)

### 1. Environment Setup

* Clone this repo (or fork if preferred).
* Create a new branch: `day1-setup`.
* Ensure you have a `/logs` folder for reflections.

### 2. Sign Up for ChatGPT-5

* Visit [chat.openai.com](https://chat.openai.com).
* Create an account (Google/Microsoft/email).
* Confirm you are using **ChatGPT-5 (free or Plus, depending on access)**.
* Bookmark the site on both **desktop and mobile**.

### 3. Sign Up for Perplexity AI

* Visit [perplexity.ai](https://www.perplexity.ai).
* Create a free account.
* Explore the **‚ÄúFocus‚Äù options** (e.g., Academic, Web).

### 4. Responsible Use Primer

* Read `data_safety_checklist.md` in this repo.
* Quick rule: Only paste **public** or **non-sensitive** information into these tools.

  * ‚úÖ Safe: news articles, public gov reports, local weather alerts.
  * ‚ùå Not safe: citizen ID numbers, patient info, private financials.

### 5. What‚Äôs New in ChatGPT-5

Compared to ChatGPT-3.5, version 5 brings:

* **Improved reasoning** ‚Äî handles multi-step logic more reliably.
* **Longer memory** ‚Äî can process and recall more context in one session.
* **Better local awareness** ‚Äî more adaptive to specific country or regional prompts (but still cross-check).
* **Cleaner formatting** ‚Äî Markdown tables, lists, and structured outputs need fewer corrections.
* **Iterative adaptability** ‚Äî refines results faster when prompts are adjusted.

### 6. Run the Same Query in Both

* Choose a **local prompt**, e.g.:

  * *‚ÄúSummarize the top challenges facing {{Country}} agriculture in 2025 using government and university sources.‚Äù*
* Capture both outputs from **ChatGPT-5** and **Perplexity**.

### 7. Compare Outputs

* Which tool cited **local sources** (if any)?
* Which tool was clearer for a **non-technical reader**?
* Which produced a **cleaner, ready-to-use format**?
* Where did ChatGPT-5‚Äôs improvements stand out?

---

## üìÇ Deliverables

* Save outputs in `Day1_comparison.md` (include query + both responses).
* Add a **reflection log** in `/logs/day1.md` (use the template below).
* Commit with message: `feat: Day 1 tool setup + ChatGPT5 vs Perplexity comparison`.

---

## ‚úÖ Rubric (Self-Check)

* [ ] Accounts created successfully
* [ ] Comparison file saved in correct folder
* [ ] Reflection log added (1‚Äì2 sentences minimum per section)
* [ ] Query used was **country-specific**
* [ ] Git commit pushed with clear message
* [ ] Notes included on **ChatGPT-5 vs 3.5 improvements**

---

## üìù Reflection Template (`/logs/reflection_template.md`)

### Day X Reflection Prompts

1. **Tool Differences**

   * How did ChatGPT-5 vs. Perplexity handle your query?
   * Which would you trust more for **local accuracy**?

2. **ChatGPT-5 Improvements**

   * Did you notice differences in reasoning, formatting, or contextual awareness compared to earlier versions (3.5)?

3. **Workflow Fit**

   * How might you use each tool in a real project (policy briefings, disaster readiness, agriculture reports)?

4. **Surprises & Insights**

   * Did either tool surface a local source (gov portal, university, newspaper)?
   * Did the results confirm or challenge your assumptions?

5. **Next Iteration**

   * If you re-ran the test tomorrow, what would you change in your prompt (different sector, local language)?
   * How would you log that change in your repo?

---

## Example for Day 1 (`/logs/day1.md`)

**Tool Differences:** Perplexity cited one gov source, ChatGPT-5 gave a smoother, structured summary.
**ChatGPT-5 Improvements:** Output was more coherent and required fewer edits than I‚Äôd expect from 3.5.
**Workflow Fit:** I‚Äôd use Perplexity for stats, ChatGPT-5 for writing policy briefs.
**Surprises & Insights:** Perplexity missed ministry data, but ChatGPT-5 provided a clearer bilingual outline.
**Next Iteration:** Tomorrow I‚Äôll re-run with a hurricane-preparedness query and test local news integration.

---

Would you like me to also **add a ‚ÄúChatGPT-5 vs. Perplexity performance tracker‚Äù table** (e.g., accuracy, local sources, structure, readability) that learners can update daily through Week 1? That way they build a visible record of strengths/weaknesses across tools.
