ðŸ“¦ **Download:** [W4D22\_flowise\_chatflow.json](sandbox:/mnt/data/W4D22_flowise_chatflow.json)

### Whatâ€™s inside

* **Nodes:** Chat Input â†’ Local Files â†’ Text Splitter â†’ Ollama Embeddings â†’ Chroma â†’ Retriever â†’ Prompt â†’ LLM â†’ (Memory) â†’ Chat Output
* **Defaults:**

  * **Embeddings:** `nomic-embed-text` @ `http://localhost:11434`
  * **LLM:** `phi3:mini` (swap to `llama3.1:8b` if you want)
  * **Chroma:** collection `aimastery_w4`, persisted to `./vectorstore`
  * **File patterns:** `**/*.{md,csv,txt}` (recursively loads your repo)

### How to use

1. Open Flowise â†’ **Import** â†’ select `W4D22_flowise_chatflow.json`.
2. In the **Local Files** node, update:

   * `directory`: point it to your repo root on disk.
3. (Optional) In **LLM** node, change `model` to `llama3.1:8b`.
4. Hit **Play** on **Local Files / Chroma** nodes to index.
5. Chat in the canvas and export your flow when youâ€™re happy.

If you want, I can also generate a **companion notes file** (`W4D22_flowise_notes.md`) with placeholders for the model used, files indexed, and a sample Q\&A you can paste into your repo.
