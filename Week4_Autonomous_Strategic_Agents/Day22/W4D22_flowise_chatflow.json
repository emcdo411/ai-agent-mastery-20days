{
  "name": "W4D22 Strategic Agent (Ollama + Chroma RAG)",
  "description": "Local Flowise chatflow: Ollama + Chroma RAG over repo files",
  "nodes": [
    {
      "id": "chat_input",
      "type": "ChatInput",
      "label": "Chat Input"
    },
    {
      "id": "doc_loader",
      "type": "DocumentLoader",
      "label": "Local Files",
      "data": {
        "directory": "./",
        "glob": "**/*.{md,csv,txt}"
      }
    },
    {
      "id": "splitter",
      "type": "TextSplitter",
      "label": "Text Splitter",
      "data": {
        "chunkSize": 1000,
        "chunkOverlap": 150
      }
    },
    {
      "id": "embed",
      "type": "Embeddings",
      "label": "Ollama Embeddings",
      "data": {
        "baseUrl": "http://localhost:11434",
        "model": "nomic-embed-text"
      }
    },
    {
      "id": "chroma",
      "type": "VectorStore",
      "label": "Chroma",
      "data": {
        "collection": "aimastery_w4",
        "persistDirectory": "./vectorstore"
      }
    },
    {
      "id": "retriever",
      "type": "Retriever",
      "label": "Retriever"
    },
    {
      "id": "prompt",
      "type": "PromptTemplate",
      "label": "System Prompt",
      "data": {
        "template": "You are a Strategic AI Coach for professionals. Use ONLY retrieved repo context when possible. Cite filenames. If unsure, ask clarifying questions. Output in concise bullet points with an action list at the end."
      }
    },
    {
      "id": "llm",
      "type": "LLM",
      "label": "Ollama LLM",
      "data": {
        "baseUrl": "http://localhost:11434",
        "model": "phi3:mini"
      }
    },
    {
      "id": "memory",
      "type": "ChatMemory",
      "label": "Chat Memory",
      "data": {
        "windowSize": 5
      }
    },
    {
      "id": "chat_output",
      "type": "ChatOutput",
      "label": "Chat Output"
    }
  ],
  "edges": [
    { "source": "chat_input", "target": "doc_loader" },
    { "source": "doc_loader", "target": "splitter" },
    { "source": "splitter", "target": "embed" },
    { "source": "embed", "target": "chroma" },
    { "source": "chroma", "target": "retriever" },
    { "source": "retriever", "target": "prompt" },
    { "source": "prompt", "target": "llm" },
    { "source": "llm", "target": "memory" },
    { "source": "memory", "target": "chat_output" }
  ]
}
