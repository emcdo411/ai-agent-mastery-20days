# ğŸš€ Day 22 â€” FlowiseAI Starter: Local Strategic Agent (Ollama + Chroma RAG)

## ğŸ“Œ Objective
Build a **no-code AI agent** in FlowiseAI that runs **100% locally** with:

- **Ollama** â€” free, local LLM (`llama3.1:8b` or smaller)
- **Chroma** â€” vector search over your own repo files
- **Flowise** â€” no-code orchestration UI

By the end, youâ€™ll have:
- A Flowise chatflow running at `http://localhost:3000`
- A local Ollama model serving responses
- A Chroma retriever indexing `.md` / `.csv` files from your repo
- An exported `.json` chatflow you can commit to GitHub

â³ **Target time:** â‰¤ 30 minutes

---

## âœ… One-Time Local Setup
- **Ollama** â€” Serves local models at `http://localhost:11434`
- **FlowiseAI** â€” No-code agent builder at `http://localhost:3000`
- **Chroma** â€” Embedded, file-based vector store

---

## ğŸ›  Step-by-Step

### 1ï¸âƒ£ Install & Start Ollama (Local LLM)
**Option A â€” Windows Installer**
- Download & run **Ollama for Windows**

**Option B â€” PowerShell + Winget**
```powershell
winget install Ollama.Ollama
````

After install, ensure Ollama is running (background service).

**Pull a Model:**

* Standard:

  ```bash
  ollama pull llama3.1:8b
  ```

  (\~4â€“8 GB; better quality)
* Lightweight:

  ```bash
  ollama pull phi3:mini
  ```

  (\~1â€“2 GB; faster)
* Embeddings:

  ```bash
  ollama pull nomic-embed-text
  ```

---

### 2ï¸âƒ£ Run FlowiseAI

**Option A â€” Docker (Recommended)**

```bash
docker run -d -p 3000:3000 -e PORT=3000 \
  -v flowise_data:/root/.flowise \
  --name flowise flowiseai/flowise
```

**Option B â€” Node.js**

```bash
npx flowise start
```

Open **[http://localhost:3000](http://localhost:3000)** â€” the Flowise UI should load.

---

### 3ï¸âƒ£ Create Your Chatflow (No-Code RAG)

**Goal:** Chat with your repo as the knowledge base.

**Nodes to Add (Left Sidebar â†’ Search):**

1. **Chat Input**
2. **Document Loader â†’ Local Files**

   * Point to your repo folder
   * File types: `*.md, *.csv, *.txt`
3. **Text Splitter** (chunk size: 1000, overlap: 150)
4. **Embeddings â†’ Ollama Embeddings**

   * Model: `nomic-embed-text`
   * Base URL: `http://localhost:11434`
5. **Vector Store â†’ Chroma**

   * Collection: `aimastery_w4`
   * Persistence: `vectorstore` folder in repo
6. **Retriever** (connect to Chroma)
7. **LLM â†’ Ollama**

   * Model: `llama3.1:8b` or `phi3:mini`
   * Base URL: `http://localhost:11434`
8. **Chat Memory** (buffer, window size 5â€“10)
9. **Prompt Template** (system prompt):

   ```text
   You are a Strategic AI Coach for professionals. Use ONLY retrieved repo context when possible.
   Cite filenames. If unsure, ask clarifying questions.
   Output in concise bullet points with an action list at the end.
   ```
10. **Chat Output**

**Wiring:**

```
Chat Input
â†’ Document Loader
â†’ Text Splitter
â†’ Embeddings
â†’ Chroma (Vector Store)
â†’ Retriever
â†’ Prompt Template
â†’ LLM
â†’ Chat Memory (optional before LLM if history needed)
â†’ Chat Output
```

**Index Your Repo:**
Click **Play** on Chroma / Document Loader nodes to ingest files.

---

### 4ï¸âƒ£ Test Prompts

* `"From this repo, what are the deliverables due in Week 2, and how do I validate them?"`
* `"Create a prep checklist for Day 21 with references to specific files."`
* `"Summarize Week 1 outcomes for an MBA student vs a military transitioner â€” cite filenames."`

---

### 5ï¸âƒ£ Export Your Chatflow

* Menu **â‹®** â†’ **Export** â†’ save as `W4D22_flowise_chatflow.json`
* *(Optional)* Screenshot â†’ save as `W4D22_flowise_screenshot.png`

---

## ğŸ“‚ Deliverables (Commit to Todayâ€™s Folder)

* `W4D22_flowise_chatflow.json` â€” chatflow export
* `W4D22_flowise_notes.md` â€” 1â€“2 paragraphs: model used, collection name, files indexed, sample Q\&A
* *(Optional)* `W4D22_flowise_screenshot.png`

---

## ğŸ§  Troubleshooting

* **Ollama not connecting?** Ensure service is running on `http://localhost:11434`
* **No files indexed?** Check file patterns; Windows may require selecting multiple folders
* **Too slow?** Switch to `phi3:mini` or reduce chunk size & Retriever Top-K (e.g., 3)

---

## ğŸ¯ Role Relevance

* **Analysts / MBA / PMP** â€” Briefings with filename citations
* **Entrepreneurs** â€” Private Q\&A over internal docs (no cloud APIs)
* **Military Transitioners** â€” Task-centric agents grounded in coursework

---

```

---

If you want, I can also turn this into a **side-by-side â€œquick setupâ€ & â€œdeep diveâ€ format** so beginners can follow the short version while advanced users get the detailed steps â€” that makes it feel even more modern and accessible.  
Do you want me to do that next?
```

