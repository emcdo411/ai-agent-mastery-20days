# âš¡ï¸ Day 18 â€” Refreshable RAG + Source-Linked Answers (Memory + Citations)

## ðŸŽ¯ Objective

Evolve your Flowise agent into a **refreshable, governance-ready knowledge system** â€” still **100% free & local**:

1. ðŸ”„ **Refresh Memory on Demand** â€” type `refresh memory` to re-index your repo (citizen reports, policies, budgets).
2. ðŸ“Ž **Source Citations by Filename** â€” every answer lists **where the info came from** (compliance & audit trail).
3. ðŸ›¡ **Guardrails** â€” confidence rating, *â€œdonâ€™t knowâ€* fallback, one clarifying question when context is thin.

â± **Timebox:** \~30 minutes

---

## âœ¨ Why This Matters (Ethiopia/Caribbean friendly)

* **Auditable** â†’ Source-linked answers build trust in public decision-making.
* **Repeatable** â†’ RAG tuned for **clean retrieval of policy docs & survey CSVs**.
* **Self-healing** â†’ Local staff can type *â€œrefresh memoryâ€* after uploading new reports â€” no IT ticket required.

Result: municipalities, NGOs, or civic orgs can **analyze policy, budget, or survey updates instantly** while keeping **data local**.

---

## ðŸ§ª Quickstart (5 minutes)

1. **Duplicate** your Day **16/17** chatflow â†’ name it `W4D18_Refreshable_RAG`.
2. **Tune retriever:**

   * Text Splitter â†’ `chunkSize=1000`, `chunkOverlap=150`
   * Retriever (Chroma) â†’ `topK=4`, **scoreThreshold** â‰ˆ `0.35â€“0.45`, search=`similarity`
   * Chroma â†’ collection: `aimastery_w4`, **upsert/update ON**
3. **Add a Router**:

   * If message **contains** `refresh memory` â†’ route to **Document Loader â†’ Splitter â†’ Embeddings â†’ Chroma (Upsert)** â†’ then output â€œMemory refreshed.â€
   * Else â†’ normal **Retriever â†’ Prompt â†’ LLM â†’ Output**
4. **Swap your Prompt** with the **Guardrails + Citations** template (below).
5. **Test** the three prompts (see bottom).

---

## ðŸ§  Prompt Template (Guardrails + Citations)

Save as `W4D18_prompt_template.txt` and paste into your **Prompt Template** node (before LLM):

```
You are a Strategic AI Coach answering ONLY with information grounded in retrieved context from this repo.

POLICY:
- If retriever returns low-similarity or no results:
  Say: "I donâ€™t have enough context in this repo to answer confidently."
  Then ask ONE clarifying question.
- Always include a "Sources" section listing file paths and/or filenames from document metadata.
- Do NOT fabricate citations, numbers, or promises.
- Keep answers crisp and decision-oriented.

FORMAT:
- Brief Answer: 3â€“6 bullets max
- Action Items: 2â€“4 bullets
- Confidence: High | Medium | Low (one short reason)
- Sources: bullet list of file paths (max 5)

CONTEXT TO USE:
{{context}}
```

---

## ðŸ§© Flow Wiring (Refresher)

**Router Branch A (Refresh Memory)**

* IF chat contains `refresh memory`
  â†’ **Document Loader (Local Files)**
  â†’ **Text Splitter**
  â†’ **Ollama Embeddings** (`nomic-embed-text`)
  â†’ **Chroma (Upsert ON)**
  â†’ **Prompt: â€œMemory refresh completeâ€¦â€**
  â†’ **Chat Output**

**Router Branch B (Normal Q\&A)**

* ELSE
  â†’ **Retriever (Chroma)**
  â†’ **Prompt (Guardrails + Citations)**
  â†’ **LLM (Ollama: `phi3:mini` or `llama3.1:8b`)**
  â†’ **Chat Output**

---

## ðŸ§± Suggested Node Texts

**â€œMemory Refreshedâ€ Prompt (Branch A)**

```
Memory refresh complete. I re-indexed the repo (Markdown/CSV/TXT).
Ask your question again for updated context.
```

**â€œCitations + Guardrailsâ€ Prompt (Branch B)**

Use `W4D18_prompt_template.txt`.

---

## ðŸ”§ Retriever Tuning (Noise â†’ Signal)

* **topK = 4** is a sweet spot for civic repos with policy docs or survey CSVs.
* **scoreThreshold 0.35â€“0.45** trims junk (raise to be stricter).
* **chunkSize=1000 / overlap=150** balances context with detail.

---

## ðŸ§ª Test Prompts (Copy into Flowise)

1. **â€œWhat are the Week 2 deliverables and how do I validate them?â€**
   *Expect:* concise bullets + **Sources** + **Confidence**.
2. **â€œSummarize Day 17 outputs for an MBA student â€” bullets + actions.â€**
   *Expect:* crisp briefing + **Sources**.
3. **Type:** `refresh memory` â†’ update a file â†’
   **â€œWhat changed in Ethiopiaâ€™s service delivery data since last refresh?â€**
   *Expect:* new **sources reflected** + updated confidence rating.

---

## ðŸ“¦ Deliverables (Day 18)

Save to `Week4_Autonomous_Strategic_Agents/Day18/`:

* `W4D18_prompt_template.txt` â€” your exact template
* `W4D18_flowise_chatflow.json` â€” exported flow
* `W4D18_tests.md` â€” paste outputs from the 3 test prompts
* *(Optional)* `W4D18_flow_screenshot.png` â€” diagram of refresh route

---

## ðŸ§° Troubleshooting

* **No Sources?** Ensure retriever includes `metadata.filePath` / `source`.
* **Refresh not working?** Confirm Router keyword, loader globs, and Chroma **Upsert** = ON.
* **Answers too long?** Lower LLM max tokens; keep `topK=3â€“4`.
* **Still noisy?** Raise threshold to `0.5`, or restrict loader to `.md` + `.csv`.

---

## ðŸ§­ Upgrade Path (Day 19â€“20 ideas)

* **Delta-diff answers:** compare pre/post refresh chunk hashes â†’ â€œwhat changedâ€ section.
* **Auto-refresh on commit:** trigger refresh when repo updates.
* **Confidence gating:** only answer if similarity â‰¥ threshold; otherwise ask one clarifying question.
* **Civic focus:** daily refresh of **budget + healthcare + citizen feedback** CSVs.

---

## ðŸ—º Diagram (Mermaid)

```mermaid
flowchart LR
  IN[Chat Input]
  R{Router: refresh memory?}
  DL[Document Loader]
  TS[Text Splitter (1000/150)]
  EMB[Embeddings (Ollama)]
  VS[Chroma (Upsert ON)]
  RET[Retriever (TopK=4, Thresh 0.35â€“0.45)]
  PTREF[Prompt: Memory Refreshed]
  PTRAG[Prompt: Guardrails + Citations]
  LLM[LLM (Ollama)]
  OUT[Chat Output]

  IN --> R
  R -- yes --> DL --> TS --> EMB --> VS --> PTREF --> OUT
  R -- no --> RET --> PTRAG --> LLM --> OUT
```

