# âš¡ï¸ Day 24 â€” Refreshable RAG + Source-Linked Answers (Memory + Citations)

## ðŸŽ¯ Objective

Give your local Flowise agent three pro-level upgradesâ€”still **100% free & local**:

1. ðŸ”„ **Refresh Memory on Demand** â€” type `refresh memory` to re-index your repo
2. ðŸ“Ž **Source Citations by Filename** â€” every answer lists where the info came from
3. ðŸ›¡ **Guardrails** â€” confidence rating, â€œdonâ€™t knowâ€ fallback, clarifying question when context is thin

â± **Timebox:** \~30 minutes

---

## âœ¨ Why This Slaps

* **Auditable** answers (with sources) ðŸ‘‰ trust + compliance
* **Repeatable** results ðŸ‘‰ clean retrieval, less noise
* **Self-healing** ðŸ‘‰ re-index from chat when docs update

---

## ðŸ§ª Quickstart (5 minutes)

1. **Duplicate** your Day 22/23 chatflow â†’ name it `W4D24_Refreshable_RAG`.
2. **Tune retriever:**

   * Text Splitter â†’ `chunkSize=1000`, `chunkOverlap=150`
   * Retriever (Chroma) â†’ `topK=4`, **Score Threshold** â‰ˆ `0.35â€“0.45`, Search=`similarity`
   * Chroma â†’ Collection:`aimastery_w4`, **Upsert/Update ON**
3. **Add Router**:

   * If message **contains** `refresh memory` â†’ route to **Document Loader â†’ Splitter â†’ Embeddings â†’ Chroma (Upsert)** â†’ then output â€œMemory refreshed.â€
   * Else â†’ normal **Retriever â†’ Prompt â†’ LLM â†’ Output**
4. **Swap your Prompt** with the **Guardrails + Citations** template below.
5. **Test** the three prompts at the bottom. Done.

---

## ðŸ§  Prompt Template (Guardrails + Citations)

Save as `W4D24_prompt_template.txt`, then paste into your **Prompt Template** node (before LLM):

```
You are a Strategic AI Coach answering ONLY with information grounded in retrieved context from this repo.

POLICY:
- If retriever returns low-similarity or no results:
  Say: "I donâ€™t have enough context in this repo to answer confidently."
  Then ask ONE clarifying question.
- Always include a "Sources" section listing file paths and/or filenames from document metadata.
- Do NOT fabricate citations, numbers, or promises.
- Keep answers crisp and decision-oriented.

FORMAT:
- Brief Answer: 3â€“6 bullets max
- Action Items: 2â€“4 bullets
- Confidence: High | Medium | Low (one short reason)
- Sources: bullet list of file paths (max 5)

CONTEXT TO USE:
{{context}}
```

> Heads up: Ensure your retriever exposes `metadata.source` or `filePath`. (In Flowise, Chroma does this; keep the field names consistent.)

---

## ðŸ§© Flow Wiring (Refresher)

**Router Branch A (Refresh Memory):**

* IF chat contains `refresh memory`
  â†’ **Document Loader (Local Files)**
  â†’ **Text Splitter**
  â†’ **Ollama Embeddings (nomic-embed-text)**
  â†’ **Chroma (Upsert ON)**
  â†’ **Prompt Template (just say: â€œMemory refresh completeâ€¦â€)**
  â†’ **Chat Output**

**Router Branch B (Normal Q\&A):**

* ELSE
  â†’ **Retriever (Chroma)**
  â†’ **Prompt Template (Guardrails + Citations)**
  â†’ **LLM (Ollama)**
  â†’ **Chat Output**

---

## ðŸ§± Suggested Node Texts

### â€œMemory Refreshedâ€ Prompt (Branch A)

```
Memory refresh complete. I re-indexed the repo (Markdown/CSV/TXT).
Ask your question again for updated context.
```

### â€œCitations + Guardrailsâ€ Prompt (Branch B)

Use `W4D24_prompt_template.txt` from above.

---

## ðŸ”§ Retriever Tuning (Noise â†’ Signal)

* **K=4** is a sweet spot for small repos
* **Score Threshold 0.35â€“0.45** trims junk (raise to be stricter)
* Keep **chunkSize=1000 / overlap=150** for markdown-heavy repos

---

## ðŸ§ª Test Prompts (Paste in Flowise)

1. **â€œWhat are the Week 2 deliverables and how do I validate them?â€**
   Expect: bullets + **Sources** + **Confidence**
2. **â€œSummarize Day 21 outputs for an MBA student â€” bullets + actions.â€**
   Expect: short, on-point brief + **Sources**
3. **Type:** `refresh memory` â†’ change a file â†’
   **â€œWhat changed in Week 2â€™s automation since last refresh?â€**
   Expect: acknowledgments + new sources reflected

---

## ðŸ“¦ Deliverables

Save to `Week4_Autonomous_Strategic_Agents/Day24/`:

* `W4D24_prompt_template.txt` â€” the exact template you used
* `W4D24_flowise_chatflow.json` â€” exported updated flow
* `W4D24_tests.md` â€” paste the 3 prompt results (copy output from Flowise)
* *(Optional)* `W4D24_flow_screenshot.png` â€” diagram of refresh route

---

## ðŸ§° Troubleshooting

* **No Sources?** Ensure retriever includes metadata + your prompt asks for Sources
* **Refresh not working?** Confirm Router keyword, loader globs, and **Chroma Upsert ON**
* **Answers too long?** Lower LLM max tokens; keep `topK=3â€“4`
* **Still noisy?** Raise threshold to `0.5`, or add a pre-filter (e.g., only `.md`)

---

## ðŸ§­ Upgrade Path (Day 25+ ideas)

* **Delta-diff answers**: compare pre/post refresh chunk hashes â†’ summarize changes
* **Auto-refresh on commit**: small watcher script hits a hidden â€œrefreshâ€ route
* **Confidence gating**: only answer if similarity â‰¥ threshold, else ask a follow-up

---

## ðŸ—º Diagram (Optional Mermaid)

If your repo renders Mermaid:

```mermaid
%%{ init: { 'theme': 'dark' } }%%
flowchart LR
  IN["ðŸ’¬ Chat Input"]
  R["âš–ï¸ Router (refresh memory?)"]
  DL["ðŸ“ Document Loader"]
  TS["âœ‚ï¸ Text Splitter (1000/150)"]
  EMB["ðŸ§¬ Embeddings (Ollama nomic-embed-text)"]
  VS["ðŸ—ƒ Chroma (Upsert ON)"]
  RET["ðŸ”Ž Retriever (TopK=4, Threshâ‰ˆ0.35â€“0.45)"]
  PTREF["ðŸ§¾ Prompt: Memory Refreshed"]
  PTRAG["ðŸ§¾ Prompt: Guardrails + Citations"]
  LLM["ðŸ§  LLM (Ollama)"]
  OUT["ðŸŸ¢ Chat Output"]

  IN --> R
  R -->|yes: 'refresh memory'| DL --> TS --> EMB --> VS --> PTREF --> OUT
  R -->|no| RET --> PTRAG --> LLM --> OUT
```
